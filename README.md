# DTAM-UIE
This repository is the official PyTorch implementation of DTAM-UIE:An Underwater Image Enhancement Method Based on Dual Transformer Aggregation and Multi-scale Feature Fusion.

Underwater suspended particles can induce light attenuation and scattering, leading to color distortion, low contrast, and blurred details in underwater imagery. This phenomenon has implications for the application of advanced visual tasks in such environments. We propose a method for underwater image processing based on dual Transformer aggregation and multi-scale feature fusion(DTAM-UIE) to address the above issues. First, underwater feature images are extracted by combining the channel self-attention Transformer(CFormer) with the Bi-level routing dynamic sparse self-attention Transformer(BiFormer). We have further enhanced the
channel self-attention mechanism by introducing additional a blueprint separable convolutions branche, enabling the Transformer to capture both global and local features effectively. Then, a parallel-channel spatial attention block is constructed to fuse features extracted by the dual Transformers. Additionally, we design a multi-scale fusion block to aggregate different scale features of the decoder part of the network model to enhance the adaptability of the network model to different underwater environments. Finally, we construct an efficient post-processing block for the U-shaped network’s output layer to fuse each part’s output features. This method effectively improves color distortion, enhances contrast, and sharpens image details. Experimental results demonstrate that this the method outperforms other qualitative and quantitative comparison methods and can better recover color and texture details
#
Environmental requirements:

